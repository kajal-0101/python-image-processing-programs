{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the neccessary packages\n",
    "import imutils\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width=647, height=388, depth=3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the input image and shows its dimensions, keeping in mind that\n",
    "# images are represented as a multi-dimensional NumPy array with\n",
    "# shape no. rows (height) x no. of columns (width) x no. of channels(depth)\n",
    "\n",
    "image = cv2.imread(\"jurassic.jpg\")\n",
    "(h, w, d) = image.shape\n",
    "print(\"width={}, height={}, depth={}\".format(w, h, d))\n",
    "\n",
    "#display the image on screen -- the window opened by OpenCv needs to be clicked\n",
    "# and a key needs to be pressed for continuing the execution\n",
    "cv2.imshow(\"Original\", image)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In OpenCv, the number of rows is the height\n",
    "* the number of columns is the width\n",
    "\n",
    "Depth is the number of channels, in this case it is 3 color channel: Blue, Green and Red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is a pixel?\n",
    "\n",
    "* Pixels are the raw building blocks of images. Images are made of pixels in grid.\n",
    "* Each pixel in a gray scale image has a value representing the shade of gray.\n",
    "* OpenCV considers the convention of BGR rather than RGB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R=27, G=45, B=31\n"
     ]
    }
   ],
   "source": [
    "# access the RGB pixel located at x=50, y=100\n",
    "# it is to be remembered that OpenCV stores images in BGR format rather than RGB\n",
    "\n",
    "(B, G, R) = image[100, 50]\n",
    "print(\"R={}, G={}, B={}\" .format(R, G, B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract a 100x100 pixel square ROI (Region Of Interest) from the\n",
    "# input image starting at x=320, y=60 and ending at x=420, y=160\n",
    "\n",
    "roi = image[60:160, 320:420]\n",
    "cv2.imshow(\"ROI\", roi)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reasons yo resize the image\n",
    "\n",
    "* to allow the image to fit on the screen\n",
    "* image processing is faster on smaller images as there are few pixels to process.\n",
    "* in the case of deep learning, often images are resized ignoring the aspect ratio, so that the vlolume fits into a network that requires an image to be square and of certain dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resize the image to 200x200px, ignoring aspect ratio\n",
    "resized = cv2.resize(image, (200, 200))\n",
    "cv2.imshow(\"Fixed Resizing\", resized)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fixed resizing distorts the aspect ratio\n",
    "#resizing the width to 300px\n",
    "#computing the new height based on the aspect ratio\n",
    "\n",
    "r = 300.0 / w\n",
    "dim = (300, int(h * r))\n",
    "resized = cv2.resize(image, dim)\n",
    "cv2.imshow(\"Aspect Ratio Resize\", resized)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manually computi8ng the aspect ratio may be time consuming\n",
    "# using the imutils library instead\n",
    "\n",
    "resized = imutils.resize(image, width=300)\n",
    "cv2.imshow(\"Imutils resize\", resized)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rotating the image 45 degress clockwise using OPenCV by first\n",
    "# computing the image center, then constructing the rotation matrix,\n",
    "# and then finally applying the affine warp\n",
    "\n",
    "center = (w//2, h//2)\n",
    "M = cv2.getRotationMatrix2D(center, -45, 1.0)\n",
    "rotated = cv2.warpAffine(image, M, (w, h))\n",
    "cv2.imshow(\"OpenCV Rotation\", rotated)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* '//' => to be used for performing integer math\n",
    "* positive angles are counter clockwise and negative angles are clockwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rotating the image using imutils library\n",
    "rotated = imutils.rotate(image, -45)\n",
    "cv2.imshow(\"Imutils Rotation\", rotated)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#OpenCV does not check if the rotated image is clipped after rotation\n",
    "# using imutils function to do away with the disadvantage\n",
    "\n",
    "rotated = imutils.rotate_bound(image, 45)\n",
    "cv2.imshow(\"Imutils Bound Rotation\", rotated)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "soemtimes an image needs to be blurred for reducing high frequency noise, making it easier for the algorithms to detect and understand the actual contents of the image rather than just noise that can confuse the algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply a Gaussian blur with a 11x11 kernel to the image to smooth it.\n",
    "# useful when reducing high frequency noise\n",
    "\n",
    "blurred = cv2.GaussianBlur(image, (11, 11), 0)\n",
    "cv2.imshow(\"Blurred\", blurred)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Larger kernel would yield a more blurry image. Smaller kernels will create less blurry images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drawing operations on images are erformed in-place.\n",
    "# at the beginning of each code block, a copy of the original image is made, storing the copy as output\n",
    "# drawing is done on the image called output\n",
    "\n",
    "output = image.copy()\n",
    "cv2.rectangle(output, (320, 60), (420, 160), (0, 0, 255), 2)\n",
    "cv2.imshow(\"Rectangle\", output)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# (320, 60) => top-left\n",
    "# (420, 160) => bottom right\n",
    "# (0, 0, 255) => color\n",
    "# 2 => thickness, negative value results in solid rectangle\n",
    "# providing value in the form of (x, y) not (y, x) as it is a OpenCV operation not a NumPy operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw a blue 20px (filled in) circle on the image centered at\n",
    "# x=300, y=150\n",
    "\n",
    "output = image.copy()\n",
    "cv2.circle(output, (300, 150), 20, (255, 0, 0), -1)\n",
    "cv2.imshow(\"Circle\", output)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# (300, 150) => center\n",
    "# 20 => radius\n",
    "# (255, 0, 0) => color\n",
    "# -1 => thickness, since the value is negative, the circle is solid/ filled in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw a 5px thick red line from x=60, y=20 to x=400, y=200\n",
    "output = image.copy()\n",
    "cv2.line(output, (60, 20), (400, 200), (0, 0, 255), 5)\n",
    "cv2.imshow(\"Line\", output)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# just as in a rectangle, two points, a color and a line thickness are supplied.\n",
    "# OpenCV's nackend does the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw green text on the image\n",
    "output = image.copy()\n",
    "cv2.putText(output, \"OPenCV + Jurassic Park!!!\", (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "cv2.imshow(\"Text\", output)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# syntax of cv2.putText()\n",
    "#cv2.putText(img, text, pt, font, scale, color, thickness)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
